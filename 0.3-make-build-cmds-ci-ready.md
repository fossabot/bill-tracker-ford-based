## Goal: One consistent set of commands that both GitHub Actions and Tekton run.



Add Gradle tasks and conventions:

* ./gradlew test

* ./gradlew check (linting later if you add it)

* ./gradlew sonar (but only in CI with env vars)

Add a minimal GitHub Actions workflow that runs:

* test

* sonar

* fossa analyze

Before we do 0.3, do this tiny alignment check:

Quick check

1. Confirm you have this file committed:

* backend/src/main/resources/application.properties

2. Confirm application-local.properties is ignored by git.


    * git status

## 0.3.1 Add SonarQube Gradle plugin + config (SonarCloud)

Open backend/build.gradle and add the SonarQube plugin and config.

A) Plugin Exists or Added

in the plugins block, add:
    * id 'org.sonarqube' version '6.0.1.5171'


B) Configure SonarCloud using environment variables

add near bottoom of backend/build.gradle:

```gradle
sonar {
    properties {
           property "sonar.host.url", "https://sonarcloud.io"
    property "sonar.projectKey", System.getenv("SONAR_PROJECT_KEY") ?: ""
    property "sonar.organization", System.getenv("SONAR_ORG") ?: ""
    property "sonar.token", System.getenv("SONAR_TOKEN") ?: ""
    }
}
```

## 0.3.2 Add GitHub Actions workflow for CI

## (what’s going on, why we do it)

### What a GitHub Actions workflow actually is

A workflow is a recipe that GitHub runs for you on every PR and on pushes to `main`.

- It runs on a clean machine (runner).
- It checks out your code.
- It runs your build commands.
- It fails the PR if the checks fail.

This turns **“it works on my laptop”** into **“it works on the repo.”**

GitHub’s own docs describe Actions as workflow automation for CI/CD.  
*(GitHub Docs)*

---

### The heuristic behind the workflow

Here’s the mental model you want to internalize so you can build these yourself later:

**Heuristic: _“One pipeline, one truth.”_**

- A developer should be able to run the same commands locally that CI runs.
- CI should mostly just “run those commands in a clean environment.”

So we structure workflow steps to match your real build gates:

1. **Build + tests**  
   Proves code compiles, tests pass

2. **Static analysis (SonarCloud)**  
   Catches code smells, bugs, coverage issues  
   *(depending on your rules)*  
   *(Sonar Documentation)*

3. **SCA (FOSSA)**  
   Checks third-party dependencies for license/security risk  
   *(FOSSA)*

That’s the whole philosophy:

- **Correctness** (tests)
- **Code quality** (Sonar)
- **Supply chain safety** (FOSSA)

---

### Why we do it in Slice 0

Because later slices (auth, bills, etc.) get complex fast. If you wait to wire CI until later, you end up **“refactoring while blind.”**

Slice 0 is about making sure every next slice is built with guardrails.


create file: .github/workflows/backend-ci.yml

```yaml 
name: backend-ci

on:
  pull_request:
    paths:
      - "backend/**"
  push:
    branches: [ main ]
    paths:
      - "backend/**"

jobs:
  build-test-scan:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: backend

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "21"

      - uses: gradle/actions/setup-gradle@v4

      - name: Test
        run: ./gradlew test

      # SonarCloud analysis
      - name: SonarCloud Scan
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_PROJECT_KEY: ${{ secrets.SONAR_PROJECT_KEY }}
          SONAR_ORG: ${{ secrets.SONAR_ORG }}
        run: ./gradlew sonar

      # FOSSA analysis
      - name: Install FOSSA CLI
        run: |
          curl -H 'Cache-Control: no-cache' https://raw.githubusercontent.com/fossas/fossa-cli/master/install.sh | bash

      - name: FOSSA Analyze
        env:
          FOSSA_API_KEY: ${{ secrets.FOSSA_API_KEY }}
        run: fossa analyze

```
### 5) What are the required things in a workflow YAML?
### Give me a cheat sheet

Think **“Workflow → Jobs → Steps”**.

---

### Minimum template

```yaml
name: <workflow name>

on:
  push:
  pull_request:

jobs:
  <job-id>:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Do a thing
        run: echo "hello"

```

Required in practice

* name (not strictly required, but you want it)

* on triggers (when it runs)
(GitHub Docs)

* jobs

* each job needs runs-on

* each job needs at least one step

* steps are either:

  * uses: an action

  * run: a shell command

Official syntax reference is here.

Heuristic

* “CI is just scripts with nice plumbing.”

* If you can run it in bash locally, you can run it in run:.


## 0.3.2 Questions

### 1) What is `actions/checkout@v4`? How would I know to choose this?

`actions/checkout` is the official GitHub Action that **downloads your repository’s code**
into the runner so later steps can run `./gradlew test`, read files, etc.  
*(GitHub)*

#### Heuristic for choosing it

- If your job needs your repo’s files, you almost always need `actions/checkout`.
- Choose the **latest major stable** (right now `v4` is a common pinned major).
- Pinning to a major avoids breaking changes that can happen with floating `latest`.
  *(GitHub)*

---

### 2) Why `ubuntu-latest`? How do I choose what to run CI on?

`runs-on: ubuntu-latest` means the job runs on a GitHub-hosted Ubuntu VM image.

GitHub documents that `-latest` images are **“latest stable”** images they provide.  
*(GitHub Docs)*

#### Heuristic

- Default to **Linux runners** unless you have a Windows-only or macOS-only need.
- Linux is usually fastest, cheapest, and closest to most cloud deployments.
- If your production runtime is Linux (common for Spring Boot), Ubuntu is the most
  aligned choice.

---

### 3) What is `actions/setup-java@v4`? How do I choose it?

`actions/setup-java` sets up a requested Java version and can also help with
Gradle tooling and caching.  
*(GitHub)*

#### Heuristic

- If you need a specific language runtime (Java 21), explicitly install it in CI.
- Choose the **official action** for the language runtime when possible.
- Pin to a **major version** (`v4`) for stability.

---

### 4) Are we setting up the environment to run our app in CI?
### Are we using containers or Docker?

Yes, we’re setting up the environment to **build and test** your backend.

But there are two different kinds of “environment” here:

---

### A) Runner environment

- `ubuntu-latest` is a VM with tools installed.
- We add Java 21 and Gradle caching so builds are consistent.

---

### B) Service dependencies environment

- Your tests need a database.
- We are **not** “running your app container” yet in Slice 0.
- We are running Postgres for tests using **Testcontainers**, which spins up
  Docker containers during test execution.

So yes, Docker is involved, but **only as a dependency provider**
(Postgres container) via Testcontainers.

Your failure confirms we haven’t fully wired that yet.

### 6) Your failing `./gradlew test` is the real problem
### (and it’s expected right now)

Your error says Spring is trying to create the application context and fails because it
cannot create a DataSource.

**Why?**

- Your default test (`contextLoads`) and your `HealthControllerTest` both start
  Spring Boot.
- Spring Boot sees JPA + Liquibase and assumes a **real DB must exist**.
- In CI, there is no DB configured in `application.properties`, so it dies.
- Locally, same story unless your `application-local.properties` profile is active.

---

### What’s the correct approach?

Tests must be **self-contained**.  
They cannot rely on “my laptop has a DB.”

So we do **two fixes**.

---

### Fix A (recommended): Make tests use Testcontainers automatically

You already have a working Testcontainers Liquibase test. Great.

Now we need to ensure **any Spring Boot test that needs a DataSource gets one**.

#### Best practice

- Add a **test-only configuration** that provides a Testcontainers Postgres for all tests.

There are two common patterns:

1. **Base test class** that other tests extend (simple and explicit)
2. **JUnit extension / `@ServiceConnection` style** (modern Spring Boot style)

We’ll do the **simplest, most readable version first**.

# Fixing `./gradlew test` failures caused by missing DB (Spring Boot + Liquibase + Testcontainers)

## Problem
Running `./gradlew test` failed in both local and CI because Spring Boot attempted to start the full application context for tests (especially the default `contextLoads()` test). Since the app includes **JPA + Liquibase**, Spring Boot expects a working **DataSource** at startup. In a clean CI runner (and on dev machines without a configured DB profile), there was **no Postgres datasource configured**, so the app failed to boot during tests.

Symptoms:
- `BillTrackerFordBasedBackendApplicationTests > contextLoads() FAILED`
- Root cause in stack trace: `DataSourceProperties$DataSourceBeanCreationException`

## Root Cause Heuristic
Spring tests come in different “weights”:

- **Slice tests** (lightweight): only load part of Spring, no DB needed.
    - Example: controller tests using `@WebMvcTest`
- **Full integration tests** (heavyweight): load the entire application context.
    - Example: `@SpringBootTest` (including the default `contextLoads()` test)

When you run a heavyweight test, you must provide **real infrastructure dependencies** (Postgres), or the test will fail on a clean machine.

## What we changed to fix it

### 1) Converted the Health endpoint test into a slice test (no DB required)
**Before**
- Health test booted a full Spring context (implicitly pulling in DataSource + Liquibase), which is unnecessary for verifying a controller response.

**After**
- Switched the health controller test to `@WebMvcTest(HealthController.class)` and used `MockMvc`.

Why this works:
- `@WebMvcTest` loads only MVC components and the specified controller.
- It does not create the JPA + Liquibase beans that require a database.

Result:
- Controller tests run fast and are isolated from database configuration.

### 2) Made `@SpringBootTest` tests use Testcontainers Postgres automatically
**Before**
- `BillTrackerFordBasedBackendApplicationTests` ran `@SpringBootTest` and tried to create a DataSource from application config.
- In CI and in local runs without the `local` profile, that datasource did not exist.
- Liquibase could not run because there was no DB connection.

**After**
- Created a shared base class `AbstractIntegrationTest` that:
    - Starts a Postgres container via Testcontainers
    - Registers datasource properties dynamically
    - Forces Liquibase to run against that container DB
    - Uses `ddl-auto=validate` to ensure Hibernate validates the Liquibase schema instead of creating its own

Then:
- Updated `BillTrackerFordBasedBackendApplicationTests` to extend the base class.

Why this works:
- Any test that boots the full app context now always gets a real Postgres DB.
- Liquibase migrations run automatically as part of the application startup in tests.
- The test environment matches CI: clean, repeatable, dependency-complete.

## Final architecture rules (what we follow going forward)

### Rule A: Use slice tests whenever possible
Use `@WebMvcTest` for controllers:
- Fast
- No DB required
- Perfect for TDD on request/response contracts

### Rule B: Only use `@SpringBootTest` when you need full integration
When using `@SpringBootTest`:
- Provide real dependencies with Testcontainers
- Do not depend on local machine DB setup
- Keep `spring.jpa.hibernate.ddl-auto=validate` to enforce schema correctness

### Rule C: CI must run the same tests as local
Goal:
- `./gradlew test` passes locally without special setup
- The same command passes on GitHub Actions and Tekton
- No hidden reliance on developer-installed Postgres or profile-only configs

## Verification commands

### Local
```bash
cd backend
./gradlew clean test



